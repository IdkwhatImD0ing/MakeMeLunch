# MakeMeLunch

## üí°Inspiration

Inspiration came from [ideas drafted below] 

‚Ä¢ ~~i was making dinner when we were discussing this~~

‚Ä¢ it's not hard to lose track of what you have/don't have and that means 1) stuff goes bad or 2) you suddenly want to make something and don't realize you don't have what you need

## üíªWhat it does

‚Ä¢ Allows a user create an account to store a list of kitchen ingredients.

‚Ä¢ List is edited through adding and removing items from search result.

‚Ä¢ Displays relevant food recipes based on a user's stored list of ingredients.

‚Ä¢ 

## üõ†Ô∏èHow we built it

‚Ä¢ React/Next.js

‚Ä¢ Javascript

‚Ä¢ Spoontacular API for food/recipe data

‚Ä¢ Firebase [for login server?]

‚Ä¢ 

## üõëChallenges we ran into

‚Ä¢ [testing sign in/sign up screen]

‚Ä¢ Lens Studio's API and Template Documentation was a bit confusing, took a while to fully understand.

‚Ä¢ Len's studio would often crash while doing preview, requiring a force quit to restart the program.

‚Ä¢ [Original Dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet) Turned out to be not official American Sign Language. Hence the high validation accuracy but low real-world accuracy. After switching to David Lee's Dataset, real world accuracy became much higher.

‚Ä¢ David Lee's dataset was very small, requiring heavy image augmentation to train a properly fitted model. Even then, some poses were unable to be recognized by the model, requiring slight shifts in posture for the model to recognize.

![Sample of Dataset](src/Dataset.png)

‚Ä¢ Original Image:

![Original](src/original.jpg)

‚Ä¢ Augmented Images:

![Augmented](src/augmented.png)

## ‚úÖAccomplishments that we're proud of

‚Ä¢ Successfully training and implementing a Machine Learning Model in an application

‚Ä¢ Used heavy image augmentation to expand the limited dataset.

‚Ä¢ Deploying a model for the first time in a brand-new environment and editor.

‚Ä¢ By using Hand Tracking, it gives the model a more precise input and also allows the lens to deactivate the model when there is no hand on the screen, preventing erroneous  predictions.

## üìñWhat we learned

‚Ä¢ JavaScript scripting

‚Ä¢ HTML formatting

‚Ä¢

## ‚ö†Ô∏è Known problems

‚Ä¢ Due to the small dataset used to train the model, some hand poses are not correctly classified. Would need a larger dataset to correct this issue.

‚Ä¢ Some letters are very similar, where the model struggles. Examples include (A/S/E) (M/N/V)

‚Ä¢ Due to J and Z requiring movement, the model is not very accurate at classifying those letters.

## üõ£Ô∏è Future Plans

‚Ä¢ Filters for time consumption and calorie intake

‚Ä¢ Further UI improvements

‚Ä¢ Options to display healthier substitutes for certain recipe ingredients 
